#!/usr/bin/env python

from __future__ import division,print_function,unicode_literals
from pentago import *
from geode import *
from geode.value import parser
from BaseHTTPServer import BaseHTTPRequestHandler,HTTPServer
from contextlib import contextmanager
import logging
import cloud
import time
import json
import re

# Properties
props = PropManager()
props.add('port',80).set_help('port to listen on')
props.add('log','').set_required(1).set_help('log file')
props.add('bits',22).set_help('size of transposition table in bits (actual size is 80<<bits)')
props.add('cache','256M').set_help('size of block cache (suffices M/MB and G/GB are understood)')
props.add('max_slice',18).set_help('maximum slice available in database (for debugging use only)')
parser.parse(props,'Perfect pentago server')

# Configure logging
log = logging.getLogger('pentago/web/server')
log.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
for handler in logging.FileHandler(props.log()),logging.StreamHandler():
  handler.setFormatter(formatter)
  log.addHandler(handler) 
log.info('command = %s'%parser.command(props,drop_defaults=False))

@contextmanager
def scope(name):
  log.info(name)
  try:
    yield
  except:
    log.exception(name)
    raise
  else:
    log.info(name+' - done')

# Prepare for opening book lookups
with scope('init block cache'):
  init_threads(1,1)
  readers = []
  for slice in xrange(props.max_slice()+1):
    with scope('init slice %d'%slice):
      readers.extend(cloud.cloud_slice(slice))
  m = re.match(r'^(\d+)(M|MB|G|GB)$',props.cache())
  if not m:
    raise RuntimeError('invalid cache size %s, expect something like 256M or 1G'%props.cache())
  size = int(m.group(1))<<{'M':20,'G':30}[m.group(2)[0]]
  log.info('cache size = %d (%s)',size,props.cache())
  cache = reader_block_cache(readers,size)

# Prepare for tree searches
with scope('init supertable'):
  init_supertable(props.bits())

# A board is either <int> (player to place) or <int>m (mid move: player to rotate)
board_path_pattern = re.compile(r'^/(\d+)(m?)$')

class Handler(BaseHTTPRequestHandler):
  def do_GET(self):
    try:
      log.info('path %s',self.path)

      # Parse board
      m = board_path_pattern.match(self.path)
      if not m:
        log.error('invalid path %s',self.path)
        self.send_error(404,'invalid path: expect /\d+m? for board, middle')
        return
      try:
        board = high_board_t(int(m.group(1)),bool(m.group(2)))
      except:
        log.exception('invalid board %s',self.path[1:])
        self.send_error(404,'invalid position %s'%self.path[1:])
        return

      # For now, always look up all immediate child values
      with scope('analyzing board %s, turn %d, slice %d'%(board,board.turn,board.count)):
        results = {}
        results['done'] = board.done()
        if board.done():
          results[str(board)] = board.value(cache) # cache isn't used since we're done
        else:
          for move in board.moves():
            if str(move) not in results:
              with scope('compute board %s, move %s'%(str(board),str(move))):
                value = move.value(cache)
                log.info('move %s, value %d',str(move),value)
                results[str(move)] = value

      # Send reply, following cache advice at https://developers.google.com/speed/docs/best-practices/caching
      self.send_response(200)
      self.send_header('content-type','application/json')
      self.send_header('cache-control','public')
      one_year_later = time.time()+365*24*60*60
      self.send_header('expires',time.strftime('%a, %d-%b-%Y %T GMT',time.gmtime(one_year_later)))
      self.end_headers()
      self.wfile.write(json.dumps(results))

    except:
      log.exception('error for path %s',self.path)
      self.send_error(500,'internal error')

# Launch server
with scope('init http server, port %d'%props.port()):
  server = HTTPServer(('',props.port()),Handler)
with scope('serve forever'):
  server.serve_forever()
