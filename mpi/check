#!/usr/bin/env python
# Verify the results of an MPI run against old out-of-core data

from __future__ import division
from pentago import *
from pentago.section import *
from other.core import *
from other.core.utility import Log
from other.core.value import parser

# Parse properties
props = PropManager()
old_dir = props.add('old','../old-data-15july2012')
dir = props.add('dir','data').set_required(1)
meaningless = props.add('meaningless',0)
parser.parse(props,'Compare MPI results with out-of-core results',positional=[dir])
old_dir = old_dir()
dir = os.path.normpath(dir())
meaningless = meaningless()

# Configure logging and threads
Log.configure('check mpi',False,False,100)
init_threads(-1,-1)

# Generate meaningless data
if meaningless:
  sections = all_boards_sections(meaningless,8)
  partition = partition_t(1,meaningless,sections,False)
  with Log.scope('meaningless'):
    cache = store_block_cache(meaningless_block_store(partition,0,0),1<<30)
  set_block_cache(cache)

# Process each slice that exists, keeping track of which files we've checked
unchecked = set(os.path.join(dir,f) for f in os.listdir(dir) if f not in 'log empty.pentago' and not f.startswith('history'))
random = Random(8183131)
init_supertable(16)
for slice in arange(36):
  counts_file = '%s/counts-%d.npy'%(dir,slice)
  sparse_file = '%s/sparse-%d.npy'%(dir,slice)
  slice_file = '%s/slice-%d.pentago'%(dir,slice)
  if os.path.exists(counts_file):
    with Log.scope('check slice %d'%slice):
      # Read sparse samples
      samples = load(sparse_file)
      assert samples.shape[1]==9
      assert samples.dtype==uint64
      sample_boards = samples[:,0].copy()
      sample_wins = samples[:,1:].copy().reshape(-1,2,4)
      unchecked.remove(sparse_file)

      # Read counts and sparse samples
      counts = load(counts_file)
      assert samples.shape[0]==256*counts.shape[0]
      assert counts.shape[1]==4
      assert counts.dtype==uint64
      Log.write('sections = %s'%' '.join(map(show_section,counts[:,0].copy().view(uint8).reshape(-1,4,2))))
      unchecked.remove(counts_file)

      # Compare against superengine
      with Log.scope('validity'):
        endgame_sparse_verify(sample_boards,sample_wins,random,len(sample_boards))

      # Open slice file
      if os.path.exists(slice_file):
        readers = open_supertensors(slice_file)
        assert 20+3*4+sum(reader.total_size() for reader in readers)==os.stat(slice_file).st_size
        assert counts.shape==(len(readers),4)
        unchecked.remove(slice_file)

        # Check each section and block
        with Log.scope('consistency'):
          for reader,counts in zip(readers,counts):
            section = reader.header.section
            assert all(section==counts[:1].view(uint8).reshape(4,2))
            old_reader = None if meaningless or not old_dir else supertensor_reader_t('%s/section-%s.pentago'%(old_dir,show_section(section)))
            counts2,samples_found = compare_readers_and_samples(reader,old_reader,sample_boards,sample_wins)
            assert all(counts[1:]==counts2)
            assert samples_found==256
      else:
        Log.write('WARNING: No slice file found, skipping consistency check for slice %d'%slice)


# Yell if any files remain
if unchecked:
  print 'strange files: %s'%' '.join(sorted(unchecked))
  assert False
