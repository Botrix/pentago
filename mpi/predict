#!/usr/bin/env python

from __future__ import division
from other.core import *
from other.core.value import parser
from pentago import *
from pentago.section import *
import re

# Mimic options to endgame-mpi
props = PropManager()
ranks = props.add('ranks',0).set_required(True)
threads = props.add('threads',0).set_required(True)
block_size = props.add('block_size',8)
save = props.add('save',0).set_required(True)
dir = props.add('dir','data')
level = props.add('level',26)
memory = props.add('memory','').set_required(True)
section = props.add('section','').set_required(True)
samples = props.add('samples',128)
meaningless = props.add('meaningless',0)
parser.parse(props,'Endgame prediction script',positional=[section])

# 'Parse' simple properties
ranks = ranks()
threads = threads()
block_size = block_size()
save = save()
samples = samples()
meaningless = meaningless()

# Meaningless isn't supported by predict
if meaningless:
  raise ValueError('predict doesn\'t accept --meaningless')

# Parse memory
m = re.match('^(\d+(?:\.\d*)?|\.\d+)(M|MB|G|GB)$',memory())
if not m:
  raise ValueError('weird memory limit %s'%memory())
memory = int(float(m.group(1))*2**{'M':20,'G':30}[m.group(2)[0]])

# Parse section
m = re.match('^\D*(?:\d\d-)?(\d{8})\D*$',section())
if not m:
  raise ValueError('bad section %s'%section())
section = asarray(map(int,m.group(1))).reshape(4,2)

# Configure logging and threads
Log.configure('predict',0,0,100)
Log.write('command = %s'%parser.command(props))
init_threads(1,0)

# Dump general information
with Log.scope('parameters'):
  Log.write('ranks = %d'%ranks)
  Log.write('cores = %d'%(ranks*threads))
  Log.write('threads / rank = %d'%threads)
  Log.write('section = %s'%show_section(section))
  Log.write('block size = %d'%block_size)
  Log.write('saved slices = %d'%save)
  Log.write('memory limit = %s'%large(memory))

line_cost = 2*64*8**3*420
def line_parallelism(base_memory):
  return (memory-base_memory)/line_cost
speed_estimate = 455092

# Limit the number of per rank blocks for tag purposes
block_limit = 2**17-1

# Simulate execution
slices = descendent_sections(section,35)
prev_partition = None
max_blocks = 0
max_base_memory = 0
min_lines = 1<<30
max_total_memory = 0
max_save_memory = 0
total_outputs = total_inputs = 0
for slice in reversed(xrange(len(slices))):
  if not len(slices[slice]):
    break
  with Log.scope('slice %d'%slice):
    partition = partition_t(ranks,slice,slices[slice],True)
    total_outputs += partition.total_nodes
    total_inputs += prev_partition.total_nodes if prev_partition else 0
    Log.write('blocks = %d'%partition.max_rank_blocks)
    Log.write('nodes = %d'%partition.max_rank_nodes)
    max_blocks = max(max_blocks,partition.max_rank_blocks)
    if partition.max_rank_blocks>=block_limit:
      raise RuntimeError('max rank blocks = %d > %d'%(partition.max_rank_blocks,block_limit))
    base_memory = max_rank_memory_usage(prev_partition,partition)
    max_base_memory = max(max_base_memory,base_memory)
    Log.write('base memory = %s'%large(base_memory))
    lines = line_parallelism(base_memory)
    min_lines = min(min_lines,lines)
    Log.write('line parallelism = %g'%lines)
    total_memory = base_memory+line_cost*max(0,int(floor(lines)))
    max_total_memory = max(max_total_memory,total_memory)
    Log.write('total memory = %s'%large(total_memory))
    prev_partition = partition
    if slice<=save:
      save_memory = 64*partition.max_rank_nodes
      Log.write('save memory = %s'%large(save_memory))
      max_save_memory = max(max_save_memory,save_memory)
with Log.scope('summary'):
  Log.write('blocks = %d'%max_blocks)
  Log.write('base memory = %s'%large(max_base_memory))
  Log.write('line parallelism = %g'%min_lines)
  Log.write('total memory = %s'%large(max_total_memory))
  Log.write('save memory = %s'%large(max_save_memory))
  Log.write('time estimate = %g s'%((total_outputs+total_inputs)/speed_estimate/ranks/threads))
